{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eHNf7J680XF-"
      },
      "source": [
        "### Word Embedding Techniques using Embedding Layer in Keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "PEsK0_yl0XGB"
      },
      "outputs": [],
      "source": [
        "### Libraries USed Tensorflow> 2.0  and keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pslw1Ya90XGC",
        "outputId": "de66f2dd-43d6-4477-9fb8-4ed421b4cbe4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting tensorflow-gpu\n",
            "  Using cached tensorflow-gpu-2.12.0.tar.gz (2.6 kB)\n",
            "  Installing build dependencies: started\n",
            "  Installing build dependencies: finished with status 'done'\n",
            "  Getting requirements to build wheel: started\n",
            "  Getting requirements to build wheel: finished with status 'error'\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  error: subprocess-exited-with-error\n",
            "  \n",
            "  × Getting requirements to build wheel did not run successfully.\n",
            "  │ exit code: 1\n",
            "  ╰─> [58 lines of output]\n",
            "      Traceback (most recent call last):\n",
            "        File \"C:\\Users\\bhong\\AppData\\Local\\Temp\\pip-build-env-fw9ehuwj\\overlay\\Lib\\site-packages\\setuptools\\_vendor\\packaging\\requirements.py\", line 36, in __init__\n",
            "          parsed = _parse_requirement(requirement_string)\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "        File \"C:\\Users\\bhong\\AppData\\Local\\Temp\\pip-build-env-fw9ehuwj\\overlay\\Lib\\site-packages\\setuptools\\_vendor\\packaging\\_parser.py\", line 62, in parse_requirement\n",
            "          return _parse_requirement(Tokenizer(source, rules=DEFAULT_RULES))\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "        File \"C:\\Users\\bhong\\AppData\\Local\\Temp\\pip-build-env-fw9ehuwj\\overlay\\Lib\\site-packages\\setuptools\\_vendor\\packaging\\_parser.py\", line 80, in _parse_requirement\n",
            "          url, specifier, marker = _parse_requirement_details(tokenizer)\n",
            "                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "        File \"C:\\Users\\bhong\\AppData\\Local\\Temp\\pip-build-env-fw9ehuwj\\overlay\\Lib\\site-packages\\setuptools\\_vendor\\packaging\\_parser.py\", line 124, in _parse_requirement_details\n",
            "          marker = _parse_requirement_marker(\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "        File \"C:\\Users\\bhong\\AppData\\Local\\Temp\\pip-build-env-fw9ehuwj\\overlay\\Lib\\site-packages\\setuptools\\_vendor\\packaging\\_parser.py\", line 145, in _parse_requirement_marker\n",
            "          tokenizer.raise_syntax_error(\n",
            "        File \"C:\\Users\\bhong\\AppData\\Local\\Temp\\pip-build-env-fw9ehuwj\\overlay\\Lib\\site-packages\\setuptools\\_vendor\\packaging\\_tokenizer.py\", line 167, in raise_syntax_error\n",
            "          raise ParserSyntaxError(\n",
            "      packaging._tokenizer.ParserSyntaxError: Expected end or semicolon (after name and no valid version specifier)\n",
            "          python_version>\"3.7\"\n",
            "                        ^\n",
            "      \n",
            "      The above exception was the direct cause of the following exception:\n",
            "      \n",
            "      Traceback (most recent call last):\n",
            "        File \"C:\\Users\\bhong\\anaconda3\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\", line 389, in <module>\n",
            "          main()\n",
            "        File \"C:\\Users\\bhong\\anaconda3\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\", line 373, in main\n",
            "          json_out[\"return_val\"] = hook(**hook_input[\"kwargs\"])\n",
            "                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "        File \"C:\\Users\\bhong\\anaconda3\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\", line 143, in get_requires_for_build_wheel\n",
            "          return hook(config_settings)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^\n",
            "        File \"C:\\Users\\bhong\\AppData\\Local\\Temp\\pip-build-env-fw9ehuwj\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 331, in get_requires_for_build_wheel\n",
            "          return self._get_build_requires(config_settings, requirements=[])\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "        File \"C:\\Users\\bhong\\AppData\\Local\\Temp\\pip-build-env-fw9ehuwj\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 301, in _get_build_requires\n",
            "          self.run_setup()\n",
            "        File \"C:\\Users\\bhong\\AppData\\Local\\Temp\\pip-build-env-fw9ehuwj\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 512, in run_setup\n",
            "          super().run_setup(setup_script=setup_script)\n",
            "        File \"C:\\Users\\bhong\\AppData\\Local\\Temp\\pip-build-env-fw9ehuwj\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 317, in run_setup\n",
            "          exec(code, locals())\n",
            "        File \"<string>\", line 40, in <module>\n",
            "        File \"C:\\Users\\bhong\\AppData\\Local\\Temp\\pip-build-env-fw9ehuwj\\overlay\\Lib\\site-packages\\setuptools\\__init__.py\", line 114, in setup\n",
            "          _install_setup_requires(attrs)\n",
            "        File \"C:\\Users\\bhong\\AppData\\Local\\Temp\\pip-build-env-fw9ehuwj\\overlay\\Lib\\site-packages\\setuptools\\__init__.py\", line 85, in _install_setup_requires\n",
            "          dist.parse_config_files(ignore_option_errors=True)\n",
            "        File \"C:\\Users\\bhong\\AppData\\Local\\Temp\\pip-build-env-fw9ehuwj\\overlay\\Lib\\site-packages\\setuptools\\dist.py\", line 758, in parse_config_files\n",
            "          self._finalize_requires()\n",
            "        File \"C:\\Users\\bhong\\AppData\\Local\\Temp\\pip-build-env-fw9ehuwj\\overlay\\Lib\\site-packages\\setuptools\\dist.py\", line 382, in _finalize_requires\n",
            "          self._normalize_requires()\n",
            "        File \"C:\\Users\\bhong\\AppData\\Local\\Temp\\pip-build-env-fw9ehuwj\\overlay\\Lib\\site-packages\\setuptools\\dist.py\", line 400, in _normalize_requires\n",
            "          self.install_requires = list_(map(str, _reqs.parse(install_requires)))\n",
            "                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "        File \"C:\\Users\\bhong\\AppData\\Local\\Temp\\pip-build-env-fw9ehuwj\\overlay\\Lib\\site-packages\\setuptools\\_vendor\\packaging\\requirements.py\", line 38, in __init__\n",
            "          raise InvalidRequirement(str(e)) from e\n",
            "      packaging.requirements.InvalidRequirement: Expected end or semicolon (after name and no valid version specifier)\n",
            "          python_version>\"3.7\"\n",
            "                        ^\n",
            "      [end of output]\n",
            "  \n",
            "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "ERROR: Failed to build 'tensorflow-gpu' when getting requirements to build wheel\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow-gpu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yZ5hceiMAX7n",
        "outputId": "f8adfe31-96ee-4fa1-b3b9-17edc8bb3ee8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.17.0\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "k4nKifUl0XGC"
      },
      "outputs": [],
      "source": [
        "##tensorflow >2.0\n",
        "from tensorflow.keras.preprocessing.text import one_hot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hADTdqZTAUfS"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Fu9PuYeu0XGD"
      },
      "outputs": [],
      "source": [
        "### sentences\n",
        "sent=[  'the glass of milk',\n",
        "     'the glass of juice',\n",
        "     'the cup of tea',\n",
        "    'I am a good boy',\n",
        "     'I am a good developer',\n",
        "     'understand the meaning of words',\n",
        "     'your videos are good']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x5d1D3_20XGD",
        "outputId": "3e3abb89-c992-4620-b332-696d5728fa3d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['the glass of milk',\n",
              " 'the glass of juice',\n",
              " 'the cup of tea',\n",
              " 'I am a good boy',\n",
              " 'I am a good developer',\n",
              " 'understand the meaning of words',\n",
              " 'your videos are good']"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "tjnXIn3B0XGE"
      },
      "outputs": [],
      "source": [
        "### Vocabulary size\n",
        "voc_size=5000"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-vQOdeKk0XGE"
      },
      "source": [
        "#### One Hot Representation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gojfZpAW0XGE",
        "outputId": "edd9dce0-84d3-4fe5-a371-121ccdb726bc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[980, 3499, 2546, 1225], [980, 3499, 2546, 1251], [980, 3799, 2546, 1722], [2458, 4742, 1600, 4001, 4079], [2458, 4742, 1600, 4001, 2509], [1789, 980, 2185, 2546, 278], [2966, 4750, 2904, 4001]]\n"
          ]
        }
      ],
      "source": [
        "onehot_repr=[one_hot(words,voc_size)for words in sent]\n",
        "print(onehot_repr)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eYG267x40XGF"
      },
      "source": [
        "### Word Embedding Represntation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "wpqPm0tb0XGF"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Embedding\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Rov3GTM00XGG"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8fQLPw6p0XGG",
        "outputId": "ce86ec66-da15-4988-e300-ff72eeb229ff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[   0    0    0    0  980 3499 2546 1225]\n",
            " [   0    0    0    0  980 3499 2546 1251]\n",
            " [   0    0    0    0  980 3799 2546 1722]\n",
            " [   0    0    0 2458 4742 1600 4001 4079]\n",
            " [   0    0    0 2458 4742 1600 4001 2509]\n",
            " [   0    0    0 1789  980 2185 2546  278]\n",
            " [   0    0    0    0 2966 4750 2904 4001]]\n"
          ]
        }
      ],
      "source": [
        "## pre padding\n",
        "sent_length=8\n",
        "embedded_docs=pad_sequences(onehot_repr,padding='pre',maxlen=sent_length)\n",
        "print(embedded_docs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "yjQqBYac0XGG"
      },
      "outputs": [],
      "source": [
        "## 10 feature dimesnions\n",
        "dim=10\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "ozC-TXrt0XGG"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\bhong\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "model=Sequential()\n",
        "model.add(Embedding(voc_size,10,input_length=sent_length))\n",
        "model.compile('adam','mse')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tMNvq-Ji0XGH",
        "outputId": "8bde65d1-06cf-4f8b-9767-28077ff2aeca"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FC4Ess_FEcb3",
        "outputId": "e35d2a7c-ff4b-4332-c2c2-dc32249595a6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([   0,    0,    0,    0,  980, 3499, 2546, 1225])"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "##'the glass of milk',\n",
        "embedded_docs[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bRqEvMBYEZUS",
        "outputId": "021bd422-238e-4a3f-daa2-09323ef3153a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 370ms/step\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([[-0.04559306,  0.03794898, -0.00989593, -0.03996627,  0.03107071,\n",
              "         0.04835881,  0.01681845, -0.04175357,  0.03346901,  0.00275704],\n",
              "       [-0.04559306,  0.03794898, -0.00989593, -0.03996627,  0.03107071,\n",
              "         0.04835881,  0.01681845, -0.04175357,  0.03346901,  0.00275704],\n",
              "       [-0.04559306,  0.03794898, -0.00989593, -0.03996627,  0.03107071,\n",
              "         0.04835881,  0.01681845, -0.04175357,  0.03346901,  0.00275704],\n",
              "       [-0.04559306,  0.03794898, -0.00989593, -0.03996627,  0.03107071,\n",
              "         0.04835881,  0.01681845, -0.04175357,  0.03346901,  0.00275704],\n",
              "       [ 0.04213593,  0.01658693, -0.00243087,  0.04851625,  0.01689906,\n",
              "         0.04389565, -0.01329237, -0.01353431,  0.00630783,  0.03515786],\n",
              "       [-0.01496093,  0.04550253,  0.02835986,  0.01301548,  0.03511998,\n",
              "         0.01210179,  0.0385632 ,  0.0134704 ,  0.03195191,  0.03668605],\n",
              "       [-0.00580394,  0.00861826,  0.02960977, -0.0374013 ,  0.01542784,\n",
              "        -0.01199962, -0.04921402, -0.04201327,  0.04628319, -0.02833744],\n",
              "       [-0.00919954, -0.03399609, -0.01200868, -0.03304193, -0.04487357,\n",
              "        -0.03491646,  0.02282384,  0.00342554, -0.04672921,  0.00259035]],\n",
              "      dtype=float32)"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.predict(embedded_docs[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kzKP69gx0XGH",
        "outputId": "4558c7ab-6692-4aa3-b958-e7bbfeb0474d"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "Exception encountered when calling Sequential.call().\n\n\u001b[1mCannot take the length of shape with unknown rank.\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=<unknown>, dtype=int32)\n  • training=False\n  • mask=None\n  • kwargs=<class 'inspect._empty'>",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[17], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(model\u001b[38;5;241m.\u001b[39mpredict(embedded_docs))\n",
            "File \u001b[1;32mc:\\Users\\bhong\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
            "File \u001b[1;32mc:\\Users\\bhong\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
            "\u001b[1;31mValueError\u001b[0m: Exception encountered when calling Sequential.call().\n\n\u001b[1mCannot take the length of shape with unknown rank.\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=<unknown>, dtype=int32)\n  • training=False\n  • mask=None\n  • kwargs=<class 'inspect._empty'>"
          ]
        }
      ],
      "source": [
        "print(model.predict(embedded_docs))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JuUxfk7d0XGH",
        "outputId": "c28e6fc6-3db2-4975-9dd3-950b7da8c67e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([   0,    0,    0,    0, 6654,  998, 8966, 1609])"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "embedded_docs[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6JJ_zD0u0XGH",
        "outputId": "8b2b65cb-457b-46f4-dd60-c5fe8ab0566f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[-0.00425554 -0.00159295 -0.04714153  0.04425247 -0.00973954 -0.04325813\n",
            "   0.04007108 -0.0143286  -0.03659749 -0.02379028]\n",
            " [-0.00425554 -0.00159295 -0.04714153  0.04425247 -0.00973954 -0.04325813\n",
            "   0.04007108 -0.0143286  -0.03659749 -0.02379028]\n",
            " [-0.00425554 -0.00159295 -0.04714153  0.04425247 -0.00973954 -0.04325813\n",
            "   0.04007108 -0.0143286  -0.03659749 -0.02379028]\n",
            " [-0.00425554 -0.00159295 -0.04714153  0.04425247 -0.00973954 -0.04325813\n",
            "   0.04007108 -0.0143286  -0.03659749 -0.02379028]\n",
            " [-0.03786323 -0.02628061  0.02974111 -0.03307171  0.0271405   0.00945134\n",
            "   0.02378127  0.04176904  0.00514941  0.0152082 ]\n",
            " [ 0.04834186  0.04388311 -0.02802253 -0.01475487 -0.01212303  0.03762435\n",
            "  -0.01166249 -0.02141088  0.04654533  0.01537322]\n",
            " [ 0.03276015 -0.00637691  0.03907344 -0.01912468  0.02177186 -0.04630325\n",
            "   0.00800942 -0.03115667 -0.00486455 -0.04843524]\n",
            " [-0.04173617  0.03438064  0.02880521 -0.01896455  0.0323303  -0.00109453\n",
            "  -0.01675171 -0.00941917 -0.03309294 -0.04779492]]\n"
          ]
        }
      ],
      "source": [
        "print(model.predict(embedded_docs)[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8OMu3iAz0XGH"
      },
      "outputs": [],
      "source": [
        "### Assignment\n",
        "\n",
        "sent=[\"The world is a better place\",\n",
        "      \"Marvel series is my favourite movie\",\n",
        "      \"I like DC movies\",\n",
        "      \"the cat is eating the food\",\n",
        "      \"Tom and Jerry is my favourite movie\",\n",
        "      \"Python is my favourite programming language\"\n",
        "      ]"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
