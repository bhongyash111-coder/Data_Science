{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eHNf7J680XF-"
   },
   "source": [
    "### Word Embedding Techniques using Embedding Layer in Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "PEsK0_yl0XGB"
   },
   "outputs": [],
   "source": [
    "### Libraries USed Tensorflow> 2.0  and keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pslw1Ya90XGC",
    "outputId": "19a2d792-fea4-4fa9-d7ee-ddd93631183d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow-gpu\n",
      "  Using cached tensorflow-gpu-2.12.0.tar.gz (2.6 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'error'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  Getting requirements to build wheel did not run successfully.\n",
      "  exit code: 1\n",
      "  \n",
      "  [58 lines of output]\n",
      "  Traceback (most recent call last):\n",
      "    File \"C:\\Users\\bhong\\AppData\\Local\\Temp\\pip-build-env-kxlkb2by\\overlay\\Lib\\site-packages\\setuptools\\_vendor\\packaging\\requirements.py\", line 36, in __init__\n",
      "      parsed = _parse_requirement(requirement_string)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    File \"C:\\Users\\bhong\\AppData\\Local\\Temp\\pip-build-env-kxlkb2by\\overlay\\Lib\\site-packages\\setuptools\\_vendor\\packaging\\_parser.py\", line 62, in parse_requirement\n",
      "      return _parse_requirement(Tokenizer(source, rules=DEFAULT_RULES))\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    File \"C:\\Users\\bhong\\AppData\\Local\\Temp\\pip-build-env-kxlkb2by\\overlay\\Lib\\site-packages\\setuptools\\_vendor\\packaging\\_parser.py\", line 80, in _parse_requirement\n",
      "      url, specifier, marker = _parse_requirement_details(tokenizer)\n",
      "                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    File \"C:\\Users\\bhong\\AppData\\Local\\Temp\\pip-build-env-kxlkb2by\\overlay\\Lib\\site-packages\\setuptools\\_vendor\\packaging\\_parser.py\", line 124, in _parse_requirement_details\n",
      "      marker = _parse_requirement_marker(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    File \"C:\\Users\\bhong\\AppData\\Local\\Temp\\pip-build-env-kxlkb2by\\overlay\\Lib\\site-packages\\setuptools\\_vendor\\packaging\\_parser.py\", line 145, in _parse_requirement_marker\n",
      "      tokenizer.raise_syntax_error(\n",
      "    File \"C:\\Users\\bhong\\AppData\\Local\\Temp\\pip-build-env-kxlkb2by\\overlay\\Lib\\site-packages\\setuptools\\_vendor\\packaging\\_tokenizer.py\", line 167, in raise_syntax_error\n",
      "      raise ParserSyntaxError(\n",
      "  packaging._tokenizer.ParserSyntaxError: Expected end or semicolon (after name and no valid version specifier)\n",
      "      python_version>\"3.7\"\n",
      "                    ^\n",
      "  \n",
      "  The above exception was the direct cause of the following exception:\n",
      "  \n",
      "  Traceback (most recent call last):\n",
      "    File \"C:\\Users\\bhong\\anaconda3\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\", line 389, in <module>\n",
      "      main()\n",
      "    File \"C:\\Users\\bhong\\anaconda3\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\", line 373, in main\n",
      "      json_out[\"return_val\"] = hook(**hook_input[\"kwargs\"])\n",
      "                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    File \"C:\\Users\\bhong\\anaconda3\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\", line 143, in get_requires_for_build_wheel\n",
      "      return hook(config_settings)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^\n",
      "    File \"C:\\Users\\bhong\\AppData\\Local\\Temp\\pip-build-env-kxlkb2by\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 331, in get_requires_for_build_wheel\n",
      "      return self._get_build_requires(config_settings, requirements=[])\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    File \"C:\\Users\\bhong\\AppData\\Local\\Temp\\pip-build-env-kxlkb2by\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 301, in _get_build_requires\n",
      "      self.run_setup()\n",
      "    File \"C:\\Users\\bhong\\AppData\\Local\\Temp\\pip-build-env-kxlkb2by\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 512, in run_setup\n",
      "      super().run_setup(setup_script=setup_script)\n",
      "    File \"C:\\Users\\bhong\\AppData\\Local\\Temp\\pip-build-env-kxlkb2by\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 317, in run_setup\n",
      "      exec(code, locals())\n",
      "    File \"<string>\", line 40, in <module>\n",
      "    File \"C:\\Users\\bhong\\AppData\\Local\\Temp\\pip-build-env-kxlkb2by\\overlay\\Lib\\site-packages\\setuptools\\__init__.py\", line 114, in setup\n",
      "      _install_setup_requires(attrs)\n",
      "    File \"C:\\Users\\bhong\\AppData\\Local\\Temp\\pip-build-env-kxlkb2by\\overlay\\Lib\\site-packages\\setuptools\\__init__.py\", line 85, in _install_setup_requires\n",
      "      dist.parse_config_files(ignore_option_errors=True)\n",
      "    File \"C:\\Users\\bhong\\AppData\\Local\\Temp\\pip-build-env-kxlkb2by\\overlay\\Lib\\site-packages\\setuptools\\dist.py\", line 758, in parse_config_files\n",
      "      self._finalize_requires()\n",
      "    File \"C:\\Users\\bhong\\AppData\\Local\\Temp\\pip-build-env-kxlkb2by\\overlay\\Lib\\site-packages\\setuptools\\dist.py\", line 382, in _finalize_requires\n",
      "      self._normalize_requires()\n",
      "    File \"C:\\Users\\bhong\\AppData\\Local\\Temp\\pip-build-env-kxlkb2by\\overlay\\Lib\\site-packages\\setuptools\\dist.py\", line 400, in _normalize_requires\n",
      "      self.install_requires = list_(map(str, _reqs.parse(install_requires)))\n",
      "                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    File \"C:\\Users\\bhong\\AppData\\Local\\Temp\\pip-build-env-kxlkb2by\\overlay\\Lib\\site-packages\\setuptools\\_vendor\\packaging\\requirements.py\", line 38, in __init__\n",
      "      raise InvalidRequirement(str(e)) from e\n",
      "  packaging.requirements.InvalidRequirement: Expected end or semicolon (after name and no valid version specifier)\n",
      "      python_version>\"3.7\"\n",
      "                    ^\n",
      "  [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "ERROR: Failed to build 'tensorflow-gpu' when getting requirements to build wheel\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow-gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yZ5hceiMAX7n",
    "outputId": "1802b7d2-99fc-4d92-96fa-a2b1a7980eca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.17.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "k4nKifUl0XGC"
   },
   "outputs": [],
   "source": [
    "##tensorflow >2.0\n",
    "from tensorflow.keras.preprocessing.text import one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hADTdqZTAUfS"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Fu9PuYeu0XGD"
   },
   "outputs": [],
   "source": [
    "### sentences\n",
    "sent=[  'the glass of milk',\n",
    "     'the glass of juice',\n",
    "     'the cup of tea',\n",
    "    'I am a good boy',\n",
    "     'I am a good developer',\n",
    "     'understand the meaning of words',\n",
    "     'your videos are good']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x5d1D3_20XGD",
    "outputId": "b279485e-fe7c-4c59-ddf6-61ba4f5403a9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the glass of milk',\n",
       " 'the glass of juice',\n",
       " 'the cup of tea',\n",
       " 'I am a good boy',\n",
       " 'I am a good developer',\n",
       " 'understand the meaning of words',\n",
       " 'your videos are good']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "tjnXIn3B0XGE"
   },
   "outputs": [],
   "source": [
    "### Vocabulary size\n",
    "voc_size=500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-vQOdeKk0XGE"
   },
   "source": [
    "#### One Hot Representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gojfZpAW0XGE",
    "outputId": "f1ac4056-9c9d-496a-9ea7-955f273f2b9e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[270, 37, 398, 258], [270, 37, 398, 94], [270, 34, 398, 128], [56, 225, 188, 336, 141], [56, 225, 188, 336, 267], [56, 270, 184, 398, 317], [306, 338, 94, 336]]\n"
     ]
    }
   ],
   "source": [
    "onehot_repr=[one_hot(words,voc_size)for words in sent]\n",
    "print(onehot_repr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eYG267x40XGF"
   },
   "source": [
    "### Word Embedding Represntation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "wpqPm0tb0XGF"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "Rov3GTM00XGG"
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8fQLPw6p0XGG",
    "outputId": "5aa143cf-bddf-4b75-cb77-715ec7a1abcf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   0   0   0 270  37 398 258]\n",
      " [  0   0   0   0 270  37 398  94]\n",
      " [  0   0   0   0 270  34 398 128]\n",
      " [  0   0   0  56 225 188 336 141]\n",
      " [  0   0   0  56 225 188 336 267]\n",
      " [  0   0   0  56 270 184 398 317]\n",
      " [  0   0   0   0 306 338  94 336]]\n"
     ]
    }
   ],
   "source": [
    "## pre padding\n",
    "sent_length=8\n",
    "embedded_docs=pad_sequences(onehot_repr,padding='pre',maxlen=sent_length)\n",
    "print(embedded_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "yjQqBYac0XGG"
   },
   "outputs": [],
   "source": [
    "## 10 feature dimesnions\n",
    "dim=10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ozC-TXrt0XGG",
    "outputId": "a944cb6f-e54d-4b42-8256-a3fd22569dfe"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhong\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model=Sequential()\n",
    "model.add(Embedding(voc_size,10,input_length=sent_length))\n",
    "model.compile('adam','mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 161
    },
    "id": "tMNvq-Ji0XGH",
    "outputId": "2182b3f6-5e32-4cc8-c407-4f077e846a0a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)                │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)                │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FC4Ess_FEcb3",
    "outputId": "eb93e9a6-e763-4a26-c0e4-611f0d9eb794"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   0,   0,   0, 270,  37, 398, 258])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##'the glass of milk',\n",
    "embedded_docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bRqEvMBYEZUS",
    "outputId": "16d9649d-3527-4bea-f186-c3e9f5e5f7ba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 431ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.03987734,  0.04609909,  0.02244625, -0.00542557,  0.02433008,\n",
       "         0.04827127, -0.01565089, -0.01022401,  0.0150688 ,  0.04679796],\n",
       "       [ 0.03987734,  0.04609909,  0.02244625, -0.00542557,  0.02433008,\n",
       "         0.04827127, -0.01565089, -0.01022401,  0.0150688 ,  0.04679796],\n",
       "       [ 0.03987734,  0.04609909,  0.02244625, -0.00542557,  0.02433008,\n",
       "         0.04827127, -0.01565089, -0.01022401,  0.0150688 ,  0.04679796],\n",
       "       [ 0.03987734,  0.04609909,  0.02244625, -0.00542557,  0.02433008,\n",
       "         0.04827127, -0.01565089, -0.01022401,  0.0150688 ,  0.04679796],\n",
       "       [ 0.00559562, -0.02296668,  0.04286214,  0.01818265,  0.01155274,\n",
       "        -0.00399499,  0.04241506,  0.01884772, -0.00817076, -0.0487236 ],\n",
       "       [ 0.0438221 , -0.0008656 , -0.00052249,  0.04771031, -0.04164009,\n",
       "        -0.00611261, -0.00869145, -0.04688502, -0.01276709, -0.0316098 ],\n",
       "       [-0.00185873,  0.00961162, -0.01851965,  0.0089551 ,  0.03960344,\n",
       "         0.00447065,  0.00953121, -0.01931057, -0.01434292, -0.0150228 ],\n",
       "       [-0.01310537, -0.02855394, -0.01804384, -0.02882985,  0.03000927,\n",
       "         0.03263011, -0.04258987,  0.01131929,  0.01020534, -0.00695192]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(embedded_docs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 425
    },
    "id": "kzKP69gx0XGH",
    "outputId": "a0e3313e-cbd2-427c-c617-c5a8f12dc437"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling Sequential.call().\n\n\u001b[1mCannot take the length of shape with unknown rank.\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=<unknown>, dtype=int32)\n  • training=False\n  • mask=None\n  • kwargs=<class 'inspect._empty'>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(model\u001b[38;5;241m.\u001b[39mpredict(embedded_docs))\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "\u001b[1;31mValueError\u001b[0m: Exception encountered when calling Sequential.call().\n\n\u001b[1mCannot take the length of shape with unknown rank.\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=<unknown>, dtype=int32)\n  • training=False\n  • mask=None\n  • kwargs=<class 'inspect._empty'>"
     ]
    }
   ],
   "source": [
    "print(model.predict(embedded_docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JuUxfk7d0XGH"
   },
   "outputs": [],
   "source": [
    "embedded_docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6JJ_zD0u0XGH"
   },
   "outputs": [],
   "source": [
    "print(model.predict(embedded_docs)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8OMu3iAz0XGH"
   },
   "outputs": [],
   "source": [
    "### Assignment\n",
    "\n",
    "sent=[\"The world is a better place\",\n",
    "      \"Marvel series is my favourite movie\",\n",
    "      \"I like DC movies\",\n",
    "      \"the cat is eating the food\",\n",
    "      \"Tom and Jerry is my favourite movie\",\n",
    "      \"Python is my favourite programming language\"\n",
    "      ]"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
